{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"18zNJDuFJmI3l1DeMBJCXMS49VOwFE-vl","timestamp":1694763581755}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"8m29AnpwzWf6","executionInfo":{"status":"ok","timestamp":1695299044773,"user_tz":-360,"elapsed":6434,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"outputs":[],"source":["# Importing libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"code","source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_17L4vnDza5I","executionInfo":{"status":"ok","timestamp":1695299050035,"user_tz":-360,"elapsed":488,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"73a1a8aa-1fc3-44c7-fb26-27c9561e5b8e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Load MNIST dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"],"metadata":{"id":"tHEXg8F21I42","executionInfo":{"status":"ok","timestamp":1695299053346,"user_tz":-360,"elapsed":1293,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1044d026-1187-4084-ebd6-a849ef01d720"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 188934989.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 29373349.62it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n","100%|██████████| 1648877/1648877 [00:00<00:00, 64870336.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 2434572.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n"]}]},{"cell_type":"markdown","source":["#Using prebuilt network"],"metadata":{"id":"GInN9lga083j"}},{"cell_type":"code","source":["# Define a simple feedforward neural network\n","class NeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(NeuralNetwork, self).__init__()\n","        self.fc1 = nn.Linear(28 * 28, 128)  # Input: 28x28 image, Output: 128\n","        self.fc2 = nn.Linear(128, 64)      # Hidden layer: 128 -> 64\n","        self.fc3 = nn.Linear(64, 10)       # Output: 64 -> 10 (10 classes for MNIST)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)  # Flatten the input\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x"],"metadata":{"id":"L4K3AZ091QvO","executionInfo":{"status":"ok","timestamp":1695286596092,"user_tz":-360,"elapsed":3,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["accuracy = 0\n","for _ in range(10):\n","  # Initialize the model, loss function, and optimizer\n","  net = NeuralNetwork()\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = optim.SGD(net.parameters(), lr=0.01)\n","  num_epochs = 20\n","\n","  # Training loop\n","  for epoch in range(num_epochs):  # Number of epochs\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          inputs, labels = data\n","\n","          optimizer.zero_grad()  # Zero the parameter gradients\n","\n","          outputs = net(inputs)\n","          loss = criterion(outputs, labels)\n","          loss.backward()\n","          optimizer.step()\n","\n","          running_loss += loss.item()\n","\n","      print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","  # Testing the model\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in testloader:\n","          images, labels = data\n","          outputs = net(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy += 100 * correct / total\n","\n","print(f'Accuracy on the test set: {accuracy/10}%')"],"metadata":{"id":"iDN6ZV-a0qEI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1695289507049,"user_tz":-360,"elapsed":2745812,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"12e1434a-fd64-4851-ffd0-3222468e8310"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 1.0646822637459363\n","Epoch 2, Loss: 0.38720336750245044\n","Epoch 3, Loss: 0.3243075942974101\n","Epoch 4, Loss: 0.28836062904804755\n","Epoch 5, Loss: 0.2613736704301669\n","Epoch 6, Loss: 0.23804650472393676\n","Epoch 7, Loss: 0.21692293654801623\n","Epoch 8, Loss: 0.19863236653827018\n","Epoch 9, Loss: 0.1835961265247196\n","Epoch 10, Loss: 0.16938360715741668\n","Epoch 11, Loss: 0.15786312079863318\n","Epoch 12, Loss: 0.14715269614837126\n","Epoch 13, Loss: 0.13790533942247885\n","Epoch 14, Loss: 0.12957727304224903\n","Epoch 15, Loss: 0.1229371245660539\n","Epoch 16, Loss: 0.11551207269051436\n","Epoch 17, Loss: 0.10946826861976687\n","Epoch 18, Loss: 0.10426557182109972\n","Epoch 19, Loss: 0.09908110249652537\n","Epoch 20, Loss: 0.09440222743358503\n","Epoch 1, Loss: 1.0615172446536612\n","Epoch 2, Loss: 0.38763429551744766\n","Epoch 3, Loss: 0.32492646702062855\n","Epoch 4, Loss: 0.29172241039621805\n","Epoch 5, Loss: 0.266019630382882\n","Epoch 6, Loss: 0.24413891439673616\n","Epoch 7, Loss: 0.2247397171210315\n","Epoch 8, Loss: 0.20816407508766854\n","Epoch 9, Loss: 0.19276749521398595\n","Epoch 10, Loss: 0.17926325136696353\n","Epoch 11, Loss: 0.1681524556495551\n","Epoch 12, Loss: 0.1569836480336498\n","Epoch 13, Loss: 0.14748279045401477\n","Epoch 14, Loss: 0.13926524357564413\n","Epoch 15, Loss: 0.13160461005069682\n","Epoch 16, Loss: 0.12453405157442508\n","Epoch 17, Loss: 0.11807323998408213\n","Epoch 18, Loss: 0.11278668157796044\n","Epoch 19, Loss: 0.10675538562214387\n","Epoch 20, Loss: 0.10279530056539787\n","Epoch 1, Loss: 1.0356007312088886\n","Epoch 2, Loss: 0.3836646647309698\n","Epoch 3, Loss: 0.32417173922729137\n","Epoch 4, Loss: 0.29237452973085426\n","Epoch 5, Loss: 0.26806716017250315\n","Epoch 6, Loss: 0.2469464645012101\n","Epoch 7, Loss: 0.22691754366098438\n","Epoch 8, Loss: 0.20881505216807444\n","Epoch 9, Loss: 0.19172018623428305\n","Epoch 10, Loss: 0.17739200123401086\n","Epoch 11, Loss: 0.16472671743331432\n","Epoch 12, Loss: 0.1534081626095688\n","Epoch 13, Loss: 0.14354629386494408\n","Epoch 14, Loss: 0.13456085890825434\n","Epoch 15, Loss: 0.12705497326913165\n","Epoch 16, Loss: 0.12012043309959966\n","Epoch 17, Loss: 0.11366416499820917\n","Epoch 18, Loss: 0.10789538322509065\n","Epoch 19, Loss: 0.10273566901453458\n","Epoch 20, Loss: 0.09772571023386806\n","Epoch 1, Loss: 1.0283735336970166\n","Epoch 2, Loss: 0.38889677056879884\n","Epoch 3, Loss: 0.32490412336486235\n","Epoch 4, Loss: 0.2915753347556919\n","Epoch 5, Loss: 0.2661746169474206\n","Epoch 6, Loss: 0.24356482484971664\n","Epoch 7, Loss: 0.2240873226272399\n","Epoch 8, Loss: 0.20652672883941295\n","Epoch 9, Loss: 0.19087454821985922\n","Epoch 10, Loss: 0.17719823965973563\n","Epoch 11, Loss: 0.165066550483804\n","Epoch 12, Loss: 0.15415820639445457\n","Epoch 13, Loss: 0.14448903840599156\n","Epoch 14, Loss: 0.13617620036812195\n","Epoch 15, Loss: 0.1283944007267417\n","Epoch 16, Loss: 0.121228299298282\n","Epoch 17, Loss: 0.11497065400295674\n","Epoch 18, Loss: 0.109365210335241\n","Epoch 19, Loss: 0.10365982682827407\n","Epoch 20, Loss: 0.09867432847547569\n","Epoch 1, Loss: 1.033663584797113\n","Epoch 2, Loss: 0.384081146626203\n","Epoch 3, Loss: 0.321515525534336\n","Epoch 4, Loss: 0.2878527039769235\n","Epoch 5, Loss: 0.26295866440735394\n","Epoch 6, Loss: 0.24075348304310587\n","Epoch 7, Loss: 0.219644579599534\n","Epoch 8, Loss: 0.20158088659601553\n","Epoch 9, Loss: 0.18497110078774537\n","Epoch 10, Loss: 0.171022902546661\n","Epoch 11, Loss: 0.15867716844465687\n","Epoch 12, Loss: 0.14837393737725738\n","Epoch 13, Loss: 0.1383575927148432\n","Epoch 14, Loss: 0.1298847920866981\n","Epoch 15, Loss: 0.1229832176663188\n","Epoch 16, Loss: 0.116214022659925\n","Epoch 17, Loss: 0.11016816471510732\n","Epoch 18, Loss: 0.10406396408944624\n","Epoch 19, Loss: 0.09964216947118675\n","Epoch 20, Loss: 0.09461210752184045\n","Epoch 1, Loss: 1.0153540660704632\n","Epoch 2, Loss: 0.38499144078699005\n","Epoch 3, Loss: 0.3223909692072284\n","Epoch 4, Loss: 0.28900475796860164\n","Epoch 5, Loss: 0.26292744547382857\n","Epoch 6, Loss: 0.2395316938887527\n","Epoch 7, Loss: 0.21852738848690795\n","Epoch 8, Loss: 0.20005267554683598\n","Epoch 9, Loss: 0.18361945946746544\n","Epoch 10, Loss: 0.16936165028448297\n","Epoch 11, Loss: 0.15784110457126074\n","Epoch 12, Loss: 0.14682999374404518\n","Epoch 13, Loss: 0.13766033787415352\n","Epoch 14, Loss: 0.1294925728761184\n","Epoch 15, Loss: 0.12207804838104098\n","Epoch 16, Loss: 0.11546023231226085\n","Epoch 17, Loss: 0.10968173634229121\n","Epoch 18, Loss: 0.10480407675080844\n","Epoch 19, Loss: 0.09964777542544263\n","Epoch 20, Loss: 0.09546505600146489\n","Epoch 1, Loss: 1.0966059707883578\n","Epoch 2, Loss: 0.3846898916751337\n","Epoch 3, Loss: 0.325167376738685\n","Epoch 4, Loss: 0.2939624388033012\n","Epoch 5, Loss: 0.26987579019704483\n","Epoch 6, Loss: 0.24923028725423793\n","Epoch 7, Loss: 0.2301912894452622\n","Epoch 8, Loss: 0.21181189707283782\n","Epoch 9, Loss: 0.1962616360470303\n","Epoch 10, Loss: 0.18139221856017101\n","Epoch 11, Loss: 0.16908398327796953\n","Epoch 12, Loss: 0.1574421675859897\n","Epoch 13, Loss: 0.1478882109118836\n","Epoch 14, Loss: 0.1381134100135233\n","Epoch 15, Loss: 0.12951957491010047\n","Epoch 16, Loss: 0.1222953124990516\n","Epoch 17, Loss: 0.11568010765622293\n","Epoch 18, Loss: 0.10935809762417667\n","Epoch 19, Loss: 0.10347418005524604\n","Epoch 20, Loss: 0.09843155998698891\n","Epoch 1, Loss: 1.03809081971137\n","Epoch 2, Loss: 0.38300167588092116\n","Epoch 3, Loss: 0.32110702923175366\n","Epoch 4, Loss: 0.28531561001563377\n","Epoch 5, Loss: 0.25913690746243573\n","Epoch 6, Loss: 0.23612898310173802\n","Epoch 7, Loss: 0.21708960965800006\n","Epoch 8, Loss: 0.19988937471816534\n","Epoch 9, Loss: 0.18511183749336296\n","Epoch 10, Loss: 0.17220759645962258\n","Epoch 11, Loss: 0.1613532164946262\n","Epoch 12, Loss: 0.15098298400807292\n","Epoch 13, Loss: 0.14190782979329322\n","Epoch 14, Loss: 0.13386923498682565\n","Epoch 15, Loss: 0.1263294296859424\n","Epoch 16, Loss: 0.1198659384412679\n","Epoch 17, Loss: 0.11368948997441194\n","Epoch 18, Loss: 0.10823925768237697\n","Epoch 19, Loss: 0.10313718627169252\n","Epoch 20, Loss: 0.09844500180592002\n","Epoch 1, Loss: 0.9835976009715849\n","Epoch 2, Loss: 0.3798461860176851\n","Epoch 3, Loss: 0.32511326096364174\n","Epoch 4, Loss: 0.2947191331765926\n","Epoch 5, Loss: 0.27062257696221126\n","Epoch 6, Loss: 0.24886905094549092\n","Epoch 7, Loss: 0.2286846057128614\n","Epoch 8, Loss: 0.2103250879111257\n","Epoch 9, Loss: 0.19330145545732746\n","Epoch 10, Loss: 0.17881245692091774\n","Epoch 11, Loss: 0.1664925272673813\n","Epoch 12, Loss: 0.1554145303521075\n","Epoch 13, Loss: 0.14565627948879434\n","Epoch 14, Loss: 0.13645662701349143\n","Epoch 15, Loss: 0.12881108304100441\n","Epoch 16, Loss: 0.12128531422688445\n","Epoch 17, Loss: 0.11493268065543762\n","Epoch 18, Loss: 0.10916403658997847\n","Epoch 19, Loss: 0.10412869068867425\n","Epoch 20, Loss: 0.099247804293826\n","Epoch 1, Loss: 1.0565861666888825\n","Epoch 2, Loss: 0.38220814524937285\n","Epoch 3, Loss: 0.3222866244455263\n","Epoch 4, Loss: 0.29184947518715215\n","Epoch 5, Loss: 0.26706114854576235\n","Epoch 6, Loss: 0.24576402088202265\n","Epoch 7, Loss: 0.22591362949977042\n","Epoch 8, Loss: 0.20817164394821822\n","Epoch 9, Loss: 0.1927584619489687\n","Epoch 10, Loss: 0.1787309805348293\n","Epoch 11, Loss: 0.16662111438350127\n","Epoch 12, Loss: 0.15537901269569834\n","Epoch 13, Loss: 0.1455440777681593\n","Epoch 14, Loss: 0.13768607610935912\n","Epoch 15, Loss: 0.12949895088189542\n","Epoch 16, Loss: 0.12297995906394682\n","Epoch 17, Loss: 0.11688939844772442\n","Epoch 18, Loss: 0.11114095257662697\n","Epoch 19, Loss: 0.10567362610596234\n","Epoch 20, Loss: 0.10116448096915094\n","Accuracy on the test set: 96.633%\n"]}]},{"cell_type":"markdown","source":["# Using Custom neuron"],"metadata":{"id":"fP2zO4Ap3Ron"}},{"cell_type":"code","source":["# Making individual neuron\n","import torch.nn.init as init\n","class Neuron(torch.nn.Module):\n","    def __init__(self, input_neurons, output_neurons): # Defining the constructor to create Neuron object\n","        super(Neuron, self).__init__()\n","        self.input_neurons = input_neurons # Setting number of neurones connected for input\n","        self.output_neurons = output_neurons # Setting number of neurones connected for output\n","        xavier_scale = 1.0 / (input_neurons + output_neurons) # Calculate the Xavier initialization scale factor\n","        self.weights = nn.Parameter(init.xavier_uniform_(torch.Tensor(input_neurons, output_neurons))) # Initialize weights using Xavier initialization (uniform distribution)\n","        self.biases = nn.Parameter(torch.randn(output_neurons)) # Setting the biases (vector)\n","\n","    # Defining the function for Forward Propagation\n","    def forward(self, input):\n","        z = torch.matmul(input, self.weights) + self.biases # Carrying out: z = X.W + b\n","        return z"],"metadata":{"id":"MJ7J_1VM3Tk9","executionInfo":{"status":"ok","timestamp":1695289508518,"user_tz":-360,"elapsed":27,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Define a simple feedforward neural network\n","class CustomNeuralNetwork(nn.Module):\n","    def __init__(self):\n","        super(CustomNeuralNetwork, self).__init__()\n","        self.input_layer = Neuron(28 * 28, 128)  # Input: 28x28 image, Output: 128\n","        self.hidden_layer = Neuron(128, 64)      # Hidden layer: 128 -> 64\n","        self.output_layer = Neuron(64, 10)       # Output: 64 -> 10 (10 classes for MNIST)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)  # Flatten the input\n","        x = torch.relu(self.input_layer(x))\n","        x = torch.relu(self.hidden_layer(x))\n","        x = self.output_layer(x)\n","        return x"],"metadata":{"id":"Uopv4aGD3Z02","executionInfo":{"status":"ok","timestamp":1695289508520,"user_tz":-360,"elapsed":22,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["accuracy1 = 0\n","for _ in range(10):\n","  # Initialize the model, loss function, and optimizer\n","  net2 = CustomNeuralNetwork()\n","  criterion2 = nn.CrossEntropyLoss()\n","  optimizer2 = optim.SGD(net2.parameters(), lr=0.01)\n","\n","  # Training loop\n","  for epoch in range(num_epochs):  # Number of epochs\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          inputs, labels = data\n","\n","          optimizer2.zero_grad()  # Zero the parameter gradients\n","\n","          outputs = net2(inputs)\n","\n","          loss = criterion2(outputs, labels)\n","          loss.backward()\n","          optimizer2.step()\n","\n","          running_loss += loss.item()\n","\n","      # print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","  # Testing the model\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in trainloader:\n","          images, labels = data\n","          outputs = net2(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy1 += 100 * correct / total\n","\n","print(f'Accuracy on the test set: {accuracy1/10}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gebRCVBg3zwq","executionInfo":{"status":"ok","timestamp":1695292278122,"user_tz":-360,"elapsed":2769621,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"ff74cdec-a536-4af3-caec-96a24b216451"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.5861549405877524\n","Epoch 2, Loss: 0.3164207722697812\n","Epoch 3, Loss: 0.27022529382314253\n","Epoch 4, Loss: 0.23735887666087924\n","Epoch 5, Loss: 0.21158934520410577\n","Epoch 6, Loss: 0.1905054537488072\n","Epoch 7, Loss: 0.1735190909320135\n","Epoch 8, Loss: 0.15971598802392545\n","Epoch 9, Loss: 0.14787442533017348\n","Epoch 10, Loss: 0.13683557060997942\n","Epoch 11, Loss: 0.12808327107970266\n","Epoch 12, Loss: 0.12033230087844961\n","Epoch 13, Loss: 0.1126204323488226\n","Epoch 14, Loss: 0.10667527747004907\n","Epoch 15, Loss: 0.10018934212676657\n","Epoch 16, Loss: 0.0953339385186463\n","Epoch 17, Loss: 0.09003346243491972\n","Epoch 18, Loss: 0.08587408634617544\n","Epoch 19, Loss: 0.0818186689650755\n","Epoch 20, Loss: 0.07796278448531162\n","Epoch 1, Loss: 0.5834488441853889\n","Epoch 2, Loss: 0.30579027047416546\n","Epoch 3, Loss: 0.25977185458691515\n","Epoch 4, Loss: 0.22995392492473887\n","Epoch 5, Loss: 0.20763700451058492\n","Epoch 6, Loss: 0.18967604011630834\n","Epoch 7, Loss: 0.1742737848978879\n","Epoch 8, Loss: 0.1617585782851301\n","Epoch 9, Loss: 0.15040601958542554\n","Epoch 10, Loss: 0.14123365227808196\n","Epoch 11, Loss: 0.13270592845793663\n","Epoch 12, Loss: 0.12537935059636768\n","Epoch 13, Loss: 0.11864914221645419\n","Epoch 14, Loss: 0.11288825102519792\n","Epoch 15, Loss: 0.10680020226737552\n","Epoch 16, Loss: 0.10149909908384848\n","Epoch 17, Loss: 0.09728651232064278\n","Epoch 18, Loss: 0.09290753220762017\n","Epoch 19, Loss: 0.0884484821108422\n","Epoch 20, Loss: 0.08506657367945512\n","Epoch 1, Loss: 0.5605842098275989\n","Epoch 2, Loss: 0.3103982668473268\n","Epoch 3, Loss: 0.26346599857118336\n","Epoch 4, Loss: 0.23078342626836382\n","Epoch 5, Loss: 0.2047634398910219\n","Epoch 6, Loss: 0.18503027651776702\n","Epoch 7, Loss: 0.16793157835044206\n","Epoch 8, Loss: 0.15449231363999755\n","Epoch 9, Loss: 0.1422439166096482\n","Epoch 10, Loss: 0.13219920050170123\n","Epoch 11, Loss: 0.12391353237118993\n","Epoch 12, Loss: 0.11666730864108531\n","Epoch 13, Loss: 0.10955393465279516\n","Epoch 14, Loss: 0.10363664873925321\n","Epoch 15, Loss: 0.09853123097138396\n","Epoch 16, Loss: 0.09382064115883572\n","Epoch 17, Loss: 0.08935916264539462\n","Epoch 18, Loss: 0.08478610695246408\n","Epoch 19, Loss: 0.08073743500574025\n","Epoch 20, Loss: 0.07772773989577537\n","Epoch 1, Loss: 0.5978104567318074\n","Epoch 2, Loss: 0.3103624858470487\n","Epoch 3, Loss: 0.26236954190011724\n","Epoch 4, Loss: 0.23110037959460764\n","Epoch 5, Loss: 0.20748812847061834\n","Epoch 6, Loss: 0.1887970722671638\n","Epoch 7, Loss: 0.17182897187388146\n","Epoch 8, Loss: 0.15942004152825837\n","Epoch 9, Loss: 0.14719343071442043\n","Epoch 10, Loss: 0.13754486652222206\n","Epoch 11, Loss: 0.12800231995160327\n","Epoch 12, Loss: 0.12065388513967268\n","Epoch 13, Loss: 0.11407034358144728\n","Epoch 14, Loss: 0.10746132131459425\n","Epoch 15, Loss: 0.10244138793809328\n","Epoch 16, Loss: 0.09760378035547923\n","Epoch 17, Loss: 0.0924341301751464\n","Epoch 18, Loss: 0.08816626585170087\n","Epoch 19, Loss: 0.08454137406389374\n","Epoch 20, Loss: 0.08110382610947879\n","Epoch 1, Loss: 0.596672186703443\n","Epoch 2, Loss: 0.31989451029947574\n","Epoch 3, Loss: 0.27449078930577614\n","Epoch 4, Loss: 0.24381391767626887\n","Epoch 5, Loss: 0.21965591437908125\n","Epoch 6, Loss: 0.2004577510877014\n","Epoch 7, Loss: 0.18395861174299646\n","Epoch 8, Loss: 0.17009999129230152\n","Epoch 9, Loss: 0.15801871435712778\n","Epoch 10, Loss: 0.14789344650754796\n","Epoch 11, Loss: 0.13870397318345207\n","Epoch 12, Loss: 0.13039808076168938\n","Epoch 13, Loss: 0.12304550785420419\n","Epoch 14, Loss: 0.11598762847594361\n","Epoch 15, Loss: 0.11021124508563501\n","Epoch 16, Loss: 0.10436283989048907\n","Epoch 17, Loss: 0.09915059584496753\n","Epoch 18, Loss: 0.09465168448967307\n","Epoch 19, Loss: 0.09041195971641078\n","Epoch 20, Loss: 0.08681339073552886\n","Epoch 1, Loss: 0.5802855186942798\n","Epoch 2, Loss: 0.31294074768164776\n","Epoch 3, Loss: 0.2649465740155945\n","Epoch 4, Loss: 0.2334607098696392\n","Epoch 5, Loss: 0.20908796865501003\n","Epoch 6, Loss: 0.18852144121520045\n","Epoch 7, Loss: 0.17324200967974118\n","Epoch 8, Loss: 0.15971016568511026\n","Epoch 9, Loss: 0.14806180250749532\n","Epoch 10, Loss: 0.13771037882499731\n","Epoch 11, Loss: 0.1297197583625947\n","Epoch 12, Loss: 0.12200475444814671\n","Epoch 13, Loss: 0.11483491627551091\n","Epoch 14, Loss: 0.1087224337874032\n","Epoch 15, Loss: 0.10326481749242081\n","Epoch 16, Loss: 0.09755844228875155\n","Epoch 17, Loss: 0.09299935867438025\n","Epoch 18, Loss: 0.08888544658395543\n","Epoch 19, Loss: 0.08463672026177682\n","Epoch 20, Loss: 0.08128682471243844\n","Epoch 1, Loss: 0.6096521622018773\n","Epoch 2, Loss: 0.31847366769271873\n","Epoch 3, Loss: 0.2682765586488346\n","Epoch 4, Loss: 0.23572563163554872\n","Epoch 5, Loss: 0.2113717445202156\n","Epoch 6, Loss: 0.1913871601787902\n","Epoch 7, Loss: 0.17473447617929755\n","Epoch 8, Loss: 0.16075480279169166\n","Epoch 9, Loss: 0.1481564159113874\n","Epoch 10, Loss: 0.1380883475789415\n","Epoch 11, Loss: 0.12836743882700388\n","Epoch 12, Loss: 0.12096556161703077\n","Epoch 13, Loss: 0.11359936763137293\n","Epoch 14, Loss: 0.10696269679111617\n","Epoch 15, Loss: 0.10090457406570154\n","Epoch 16, Loss: 0.09576016208375378\n","Epoch 17, Loss: 0.09102696846964071\n","Epoch 18, Loss: 0.08665120139368561\n","Epoch 19, Loss: 0.08210838766299935\n","Epoch 20, Loss: 0.07828472929496343\n","Epoch 1, Loss: 0.6331293159075129\n","Epoch 2, Loss: 0.3270256176654464\n","Epoch 3, Loss: 0.2772873124635931\n","Epoch 4, Loss: 0.2435874125437696\n","Epoch 5, Loss: 0.21665814572544112\n","Epoch 6, Loss: 0.19418385885417588\n","Epoch 7, Loss: 0.17582330262578372\n","Epoch 8, Loss: 0.1609951528265818\n","Epoch 9, Loss: 0.14758220224627364\n","Epoch 10, Loss: 0.1375025764310252\n","Epoch 11, Loss: 0.1274844457143183\n","Epoch 12, Loss: 0.11921430444384594\n","Epoch 13, Loss: 0.11209213813798609\n","Epoch 14, Loss: 0.1055220615988506\n","Epoch 15, Loss: 0.09929887326593116\n","Epoch 16, Loss: 0.09440164353603175\n","Epoch 17, Loss: 0.09022500717154602\n","Epoch 18, Loss: 0.08528105282028124\n","Epoch 19, Loss: 0.08122319770829954\n","Epoch 20, Loss: 0.07781747085596326\n","Epoch 1, Loss: 0.5804051008623546\n","Epoch 2, Loss: 0.315076063913323\n","Epoch 3, Loss: 0.26787159784135023\n","Epoch 4, Loss: 0.23477146176815922\n","Epoch 5, Loss: 0.20758840724476366\n","Epoch 6, Loss: 0.1856882441034322\n","Epoch 7, Loss: 0.16896403670461893\n","Epoch 8, Loss: 0.15383175189203735\n","Epoch 9, Loss: 0.14182096365084654\n","Epoch 10, Loss: 0.13202380624685142\n","Epoch 11, Loss: 0.12237030649577567\n","Epoch 12, Loss: 0.11498882454424811\n","Epoch 13, Loss: 0.1080690515168043\n","Epoch 14, Loss: 0.10188443117093907\n","Epoch 15, Loss: 0.09682031844490405\n","Epoch 16, Loss: 0.09146436792500476\n","Epoch 17, Loss: 0.08755080933585319\n","Epoch 18, Loss: 0.08286334415311927\n","Epoch 19, Loss: 0.07925021790587572\n","Epoch 20, Loss: 0.07582494480781622\n","Epoch 1, Loss: 0.6037511664794198\n","Epoch 2, Loss: 0.3188957113987093\n","Epoch 3, Loss: 0.2693842218867116\n","Epoch 4, Loss: 0.23521193329379883\n","Epoch 5, Loss: 0.20923070280330142\n","Epoch 6, Loss: 0.18793084719049524\n","Epoch 7, Loss: 0.17013909372050307\n","Epoch 8, Loss: 0.1558125686666954\n","Epoch 9, Loss: 0.14356890626188154\n","Epoch 10, Loss: 0.1332492539420851\n","Epoch 11, Loss: 0.12462185659825104\n","Epoch 12, Loss: 0.11737835448560939\n","Epoch 13, Loss: 0.11014927719940128\n","Epoch 14, Loss: 0.10411227013129415\n","Epoch 15, Loss: 0.09848645864737662\n","Epoch 16, Loss: 0.09291997539507015\n","Epoch 17, Loss: 0.08894462142187332\n","Epoch 18, Loss: 0.08482970455353622\n","Epoch 19, Loss: 0.08059531253184686\n","Epoch 20, Loss: 0.07718914197777697\n","Accuracy on the test set: 97.76166666666666%\n"]}]},{"cell_type":"markdown","source":["#Using ADAM optimizer\n"],"metadata":{"id":"fzHSYRYQyur5"}},{"cell_type":"code","source":["accuracy2 = 0\n","for _ in range(10):\n","  # Initialize the model, loss function, and optimizer\n","  net3 = CustomNeuralNetwork()\n","  criterion3 = nn.CrossEntropyLoss()\n","  optimizer3 = optim.Adam(net3.parameters(), lr=0.01)  # Use Adam optimizer\n","\n","  for epoch in range(num_epochs):\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          inputs, labels = data\n","          optimizer3.zero_grad()\n","          outputs = net3(inputs)\n","          loss = criterion3(outputs, labels)\n","          loss.backward()\n","          optimizer3.step()\n","          running_loss += loss.item()\n","      # print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","  # Testing the model\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in trainloader:\n","          images, labels = data\n","          outputs = net3(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy2 += 100 * correct / total\n","\n","print(f'Accuracy on the test set: {accuracy2/10}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXlxv3ZdyynP","executionInfo":{"status":"ok","timestamp":1695295482049,"user_tz":-360,"elapsed":3203934,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"c30f91a9-e31f-4eef-b1ed-b383182f1911"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.42507387465759633\n","Epoch 2, Loss: 0.24384682282988132\n","Epoch 3, Loss: 0.23275366077807222\n","Epoch 4, Loss: 0.2211488114961826\n","Epoch 5, Loss: 0.21590695782566566\n","Epoch 6, Loss: 0.19992018235859269\n","Epoch 7, Loss: 0.20362324524682754\n","Epoch 8, Loss: 0.19119056466537943\n","Epoch 9, Loss: 0.19122110850521243\n","Epoch 10, Loss: 0.18824672815538862\n","Epoch 11, Loss: 0.18739568297939896\n","Epoch 12, Loss: 0.18424370973460327\n","Epoch 13, Loss: 0.17926120556898908\n","Epoch 14, Loss: 0.17586376555839867\n","Epoch 15, Loss: 0.16922544758431296\n","Epoch 16, Loss: 0.1786421149977044\n","Epoch 17, Loss: 0.1743166942833496\n","Epoch 18, Loss: 0.16778737585644113\n","Epoch 19, Loss: 0.17246437602853185\n","Epoch 20, Loss: 0.16727701385122246\n","Epoch 1, Loss: 0.42543609423844864\n","Epoch 2, Loss: 0.2493167309793455\n","Epoch 3, Loss: 0.22991867610878908\n","Epoch 4, Loss: 0.22224081504637244\n","Epoch 5, Loss: 0.2131222033960574\n","Epoch 6, Loss: 0.21052910514306952\n","Epoch 7, Loss: 0.19689865508523863\n","Epoch 8, Loss: 0.19742835374789308\n","Epoch 9, Loss: 0.1921346891186893\n","Epoch 10, Loss: 0.19197145355160414\n","Epoch 11, Loss: 0.1896215082356718\n","Epoch 12, Loss: 0.18212577920786338\n","Epoch 13, Loss: 0.17901658283066013\n","Epoch 14, Loss: 0.18026553253099115\n","Epoch 15, Loss: 0.16960143727555213\n","Epoch 16, Loss: 0.17266434960629243\n","Epoch 17, Loss: 0.16976246164951808\n","Epoch 18, Loss: 0.17004122600696092\n","Epoch 19, Loss: 0.1618664124459306\n","Epoch 20, Loss: 0.17210476392227758\n","Epoch 1, Loss: 0.4058510425732906\n","Epoch 2, Loss: 0.23944797323567907\n","Epoch 3, Loss: 0.21768691876867433\n","Epoch 4, Loss: 0.2042156597778106\n","Epoch 5, Loss: 0.19350239933470387\n","Epoch 6, Loss: 0.19873281387981576\n","Epoch 7, Loss: 0.1910677920711209\n","Epoch 8, Loss: 0.18610481029229442\n","Epoch 9, Loss: 0.17487894710320145\n","Epoch 10, Loss: 0.17454092552079192\n","Epoch 11, Loss: 0.17558687681387833\n","Epoch 12, Loss: 0.1670669236792319\n","Epoch 13, Loss: 0.16643596085598633\n","Epoch 14, Loss: 0.1563470709099889\n","Epoch 15, Loss: 0.17559944524113008\n","Epoch 16, Loss: 0.1511244380035932\n","Epoch 17, Loss: 0.15902541441592707\n","Epoch 18, Loss: 0.15690689386108886\n","Epoch 19, Loss: 0.15499813474420862\n","Epoch 20, Loss: 0.1631482725406735\n","Epoch 1, Loss: 0.4432888182042949\n","Epoch 2, Loss: 0.24953123006119785\n","Epoch 3, Loss: 0.2317482180067344\n","Epoch 4, Loss: 0.21171784246646203\n","Epoch 5, Loss: 0.2147215153497737\n","Epoch 6, Loss: 0.21713570688964365\n","Epoch 7, Loss: 0.20740787959250528\n","Epoch 8, Loss: 0.20383110711835564\n","Epoch 9, Loss: 0.20161946586319315\n","Epoch 10, Loss: 0.20228504859455138\n","Epoch 11, Loss: 0.1890541638787796\n","Epoch 12, Loss: 0.19073158381745092\n","Epoch 13, Loss: 0.19130646347699723\n","Epoch 14, Loss: 0.18755077932333783\n","Epoch 15, Loss: 0.18122307686353606\n","Epoch 16, Loss: 0.18740738818306785\n","Epoch 17, Loss: 0.1823973678179514\n","Epoch 18, Loss: 0.17764096642071917\n","Epoch 19, Loss: 0.17797086519628033\n","Epoch 20, Loss: 0.18869718306584718\n","Epoch 1, Loss: 0.4770191642187679\n","Epoch 2, Loss: 0.2651638802029748\n","Epoch 3, Loss: 0.2312742270338637\n","Epoch 4, Loss: 0.22058805782617982\n","Epoch 5, Loss: 0.2095795343898094\n","Epoch 6, Loss: 0.1988576028639002\n","Epoch 7, Loss: 0.19763542188486374\n","Epoch 8, Loss: 0.19668052919598214\n","Epoch 9, Loss: 0.18938175671751786\n","Epoch 10, Loss: 0.18065034945074446\n","Epoch 11, Loss: 0.18257359466426124\n","Epoch 12, Loss: 0.18951393131698882\n","Epoch 13, Loss: 0.1804210202667171\n","Epoch 14, Loss: 0.17799014324294543\n","Epoch 15, Loss: 0.16923642291604027\n","Epoch 16, Loss: 0.1719686595036952\n","Epoch 17, Loss: 0.16676934023719353\n","Epoch 18, Loss: 0.17218378995523365\n","Epoch 19, Loss: 0.16710267390515696\n","Epoch 20, Loss: 0.16556417991393316\n","Epoch 1, Loss: 0.4173711637761801\n","Epoch 2, Loss: 0.24639607368628863\n","Epoch 3, Loss: 0.22538651059320106\n","Epoch 4, Loss: 0.21076092113063596\n","Epoch 5, Loss: 0.2165078154744219\n","Epoch 6, Loss: 0.2001514015063993\n","Epoch 7, Loss: 0.21545875313451518\n","Epoch 8, Loss: 0.20109941151890673\n","Epoch 9, Loss: 0.1925533346326422\n","Epoch 10, Loss: 0.19324496932434979\n","Epoch 11, Loss: 0.19060937385422302\n","Epoch 12, Loss: 0.18325094338198666\n","Epoch 13, Loss: 0.1837871750540682\n","Epoch 14, Loss: 0.17865607674533465\n","Epoch 15, Loss: 0.17122755731259393\n","Epoch 16, Loss: 0.1694087024424662\n","Epoch 17, Loss: 0.1706328027561974\n","Epoch 18, Loss: 0.16902501452048974\n","Epoch 19, Loss: 0.1626164478707566\n","Epoch 20, Loss: 0.16724952014842268\n","Epoch 1, Loss: 0.4180113348101121\n","Epoch 2, Loss: 0.23727240837189054\n","Epoch 3, Loss: 0.234820844714782\n","Epoch 4, Loss: 0.2183800578149143\n","Epoch 5, Loss: 0.21570044231793678\n","Epoch 6, Loss: 0.2066057168745569\n","Epoch 7, Loss: 0.21492650690597734\n","Epoch 8, Loss: 0.20918093598795248\n","Epoch 9, Loss: 0.20861171804237436\n","Epoch 10, Loss: 0.1913040631772406\n","Epoch 11, Loss: 0.1946073559262772\n","Epoch 12, Loss: 0.19066221093826458\n","Epoch 13, Loss: 0.18117347388798352\n","Epoch 14, Loss: 0.1791360907550496\n","Epoch 15, Loss: 0.18256518180305356\n","Epoch 16, Loss: 0.18737692571580727\n","Epoch 17, Loss: 0.17706259646649553\n","Epoch 18, Loss: 0.17968292135957764\n","Epoch 19, Loss: 0.1838182398945397\n","Epoch 20, Loss: 0.18285578631235958\n","Epoch 1, Loss: 0.4331341739108504\n","Epoch 2, Loss: 0.2523644352887771\n","Epoch 3, Loss: 0.22360954413424805\n","Epoch 4, Loss: 0.229261709440714\n","Epoch 5, Loss: 0.2160865761595828\n","Epoch 6, Loss: 0.21411023426379985\n","Epoch 7, Loss: 0.217126120503412\n","Epoch 8, Loss: 0.20781696929947843\n","Epoch 9, Loss: 0.2081571841187505\n","Epoch 10, Loss: 0.20072748890714542\n","Epoch 11, Loss: 0.20072831203148309\n","Epoch 12, Loss: 0.1942249742447774\n","Epoch 13, Loss: 0.20329597476981023\n","Epoch 14, Loss: 0.19799418066258925\n","Epoch 15, Loss: 0.178640963015224\n","Epoch 16, Loss: 0.19603458279644503\n","Epoch 17, Loss: 0.19865156666063932\n","Epoch 18, Loss: 0.18701000551212588\n","Epoch 19, Loss: 0.18911929869813832\n","Epoch 20, Loss: 0.18753831015764746\n","Epoch 1, Loss: 0.4466436171153588\n","Epoch 2, Loss: 0.2490342139169129\n","Epoch 3, Loss: 0.24065409322529396\n","Epoch 4, Loss: 0.21842972518427411\n","Epoch 5, Loss: 0.2124334703386227\n","Epoch 6, Loss: 0.21387548836321432\n","Epoch 7, Loss: 0.21109393044218008\n","Epoch 8, Loss: 0.2115110855515816\n","Epoch 9, Loss: 0.2014577298232519\n","Epoch 10, Loss: 0.19975400077941607\n","Epoch 11, Loss: 0.1964530383429325\n","Epoch 12, Loss: 0.20192466414213847\n","Epoch 13, Loss: 0.19797570999266942\n","Epoch 14, Loss: 0.19267958750042802\n","Epoch 15, Loss: 0.19599911273478954\n","Epoch 16, Loss: 0.18858624476867952\n","Epoch 17, Loss: 0.19065968611978615\n","Epoch 18, Loss: 0.18803711083959906\n","Epoch 19, Loss: 0.18907122763006814\n","Epoch 20, Loss: 0.19256228438592446\n","Epoch 1, Loss: 0.5710695385456339\n","Epoch 2, Loss: 0.2592896513108696\n","Epoch 3, Loss: 0.21908111461618943\n","Epoch 4, Loss: 0.20936411791947732\n","Epoch 5, Loss: 0.18854747127606544\n","Epoch 6, Loss: 0.1999095721221936\n","Epoch 7, Loss: 0.18023689673431137\n","Epoch 8, Loss: 0.18274377771307712\n","Epoch 9, Loss: 0.18202048314433458\n","Epoch 10, Loss: 0.17412176365350515\n","Epoch 11, Loss: 0.17137389619405796\n","Epoch 12, Loss: 0.1677318023917859\n","Epoch 13, Loss: 0.16507702244262992\n","Epoch 14, Loss: 0.1613341052564723\n","Epoch 15, Loss: 0.15427128610902155\n","Epoch 16, Loss: 0.1657392402414852\n","Epoch 17, Loss: 0.15737071164698999\n","Epoch 18, Loss: 0.1574521241808878\n","Epoch 19, Loss: 0.1661836333669174\n","Epoch 20, Loss: 0.1551344061311561\n","Accuracy on the test set: 95.45366666666665%\n"]}]},{"cell_type":"markdown","source":["#Using Orthogonal Initialization"],"metadata":{"id":"zb1dzIalyzK8"}},{"cell_type":"code","source":["# Making individual neuron\n","import torch.nn.init as init\n","class Neuron2(torch.nn.Module):\n","    def __init__(self, input_neurons, output_neurons): # Defining the constructor to create Neuron object\n","        super(Neuron2, self).__init__()\n","        self.input_neurons = input_neurons # Setting number of neurones connected for input\n","        self.output_neurons = output_neurons # Setting number of neurones connected for output\n","        self.weights = nn.Parameter(init.orthogonal_(torch.Tensor(input_neurons, output_neurons))) # Initialize weights using Orthogonal initialization\n","        self.biases = nn.Parameter(torch.randn(output_neurons)) # Setting the biases (vector)\n","\n","    # Defining the function for Forward Propagation\n","    def forward(self, input):\n","        z = torch.matmul(input, self.weights) + self.biases # Carrying out: z = X.W + b\n","        return z"],"metadata":{"id":"ZwoW5tIly3FD","executionInfo":{"status":"ok","timestamp":1695299066449,"user_tz":-360,"elapsed":4,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define a simple feedforward neural network\n","class CustomNeuralNetwork2(nn.Module):\n","    def __init__(self):\n","        super(CustomNeuralNetwork2, self).__init__()\n","        self.input_layer = Neuron2(28 * 28, 128)  # Input: 28x28 image, Output: 128\n","        self.hidden_layer = Neuron2(128, 64)      # Hidden layer: 128 -> 64\n","        self.output_layer = Neuron2(64, 10)       # Output: 64 -> 10 (10 classes for MNIST)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28 * 28)  # Flatten the input\n","        x = torch.relu(self.input_layer(x))\n","        x = torch.relu(self.hidden_layer(x))\n","        x = self.output_layer(x)\n","        return x"],"metadata":{"id":"mFyE7Pmm3Tx2","executionInfo":{"status":"ok","timestamp":1695299068385,"user_tz":-360,"elapsed":3,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["accuracy3 = 0\n","for _ in range(10):\n","  # Initialize the model, loss function, and optimizer\n","  net4 = CustomNeuralNetwork2()\n","  criterion4 = nn.CrossEntropyLoss()\n","  optimizer4 = optim.SGD(net4.parameters(), lr=0.01)  # Use Adam optimizer\n","\n","  for epoch in range(num_epochs):\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          inputs, labels = data\n","          optimizer4.zero_grad()\n","          outputs = net4(inputs)\n","          loss = criterion4(outputs, labels)\n","          loss.backward()\n","          optimizer4.step()\n","          running_loss += loss.item()\n","      # print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","  # Testing the model\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in trainloader:\n","          images, labels = data\n","          outputs = net4(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy3 += 100 * correct / total\n","\n","print(f'Accuracy on the test set: {accuracy3/10}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1GQ3koXb3cIH","executionInfo":{"status":"ok","timestamp":1695298266193,"user_tz":-360,"elapsed":2784151,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"05bb1c48-be12-4b53-efd0-915c3afa9a30"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.654400236571013\n","Epoch 2, Loss: 0.3296374770036257\n","Epoch 3, Loss: 0.2835764469844954\n","Epoch 4, Loss: 0.2533521699204819\n","Epoch 5, Loss: 0.22870965487063566\n","Epoch 6, Loss: 0.20814303872681883\n","Epoch 7, Loss: 0.19052487848870664\n","Epoch 8, Loss: 0.1751789663102168\n","Epoch 9, Loss: 0.16220460870245626\n","Epoch 10, Loss: 0.15087633522779448\n","Epoch 11, Loss: 0.1413251772852563\n","Epoch 12, Loss: 0.13302274960587654\n","Epoch 13, Loss: 0.1248308756370852\n","Epoch 14, Loss: 0.11787993299252571\n","Epoch 15, Loss: 0.1118492706994544\n","Epoch 16, Loss: 0.10580527020205281\n","Epoch 17, Loss: 0.10038793424684514\n","Epoch 18, Loss: 0.09614151281251042\n","Epoch 19, Loss: 0.0913617080921478\n","Epoch 20, Loss: 0.08733758848331281\n","Epoch 1, Loss: 0.6924910148514359\n","Epoch 2, Loss: 0.3449405142620428\n","Epoch 3, Loss: 0.2980269226136365\n","Epoch 4, Loss: 0.2671767440972044\n","Epoch 5, Loss: 0.24157664882761837\n","Epoch 6, Loss: 0.2195204207137513\n","Epoch 7, Loss: 0.20013748774571077\n","Epoch 8, Loss: 0.18339167738249942\n","Epoch 9, Loss: 0.16875729784925483\n","Epoch 10, Loss: 0.15642925032348967\n","Epoch 11, Loss: 0.14531562990471245\n","Epoch 12, Loss: 0.1366676155870943\n","Epoch 13, Loss: 0.12758246339412768\n","Epoch 14, Loss: 0.12016460028633888\n","Epoch 15, Loss: 0.1126562171349568\n","Epoch 16, Loss: 0.1067784204006767\n","Epoch 17, Loss: 0.10232793162566925\n","Epoch 18, Loss: 0.097238539839223\n","Epoch 19, Loss: 0.09275212215045209\n","Epoch 20, Loss: 0.08848393138752246\n","Epoch 1, Loss: 0.6731052547693253\n","Epoch 2, Loss: 0.3373127546884231\n","Epoch 3, Loss: 0.29266357202249677\n","Epoch 4, Loss: 0.2639667556714465\n","Epoch 5, Loss: 0.2401786485254002\n","Epoch 6, Loss: 0.21800801394257083\n","Epoch 7, Loss: 0.19870271664787967\n","Epoch 8, Loss: 0.1821779722510688\n","Epoch 9, Loss: 0.1671579733574346\n","Epoch 10, Loss: 0.1551966974015302\n","Epoch 11, Loss: 0.1448420025249407\n","Epoch 12, Loss: 0.1352734612559141\n","Epoch 13, Loss: 0.12644286402888388\n","Epoch 14, Loss: 0.11958180234801255\n","Epoch 15, Loss: 0.11286373371119375\n","Epoch 16, Loss: 0.10725985646946852\n","Epoch 17, Loss: 0.10199178468936415\n","Epoch 18, Loss: 0.09709694386938456\n","Epoch 19, Loss: 0.09243304946664363\n","Epoch 20, Loss: 0.08821012956429837\n","Epoch 1, Loss: 0.708393654144649\n","Epoch 2, Loss: 0.3453193285873831\n","Epoch 3, Loss: 0.30080947372466643\n","Epoch 4, Loss: 0.2714936695119211\n","Epoch 5, Loss: 0.2474078136895384\n","Epoch 6, Loss: 0.22595490432624368\n","Epoch 7, Loss: 0.2076500697033619\n","Epoch 8, Loss: 0.19041691866240648\n","Epoch 9, Loss: 0.17556618051583578\n","Epoch 10, Loss: 0.16281880529871437\n","Epoch 11, Loss: 0.15156394339549834\n","Epoch 12, Loss: 0.1415838088725072\n","Epoch 13, Loss: 0.1332046465773477\n","Epoch 14, Loss: 0.12491597850391986\n","Epoch 15, Loss: 0.11824319191348515\n","Epoch 16, Loss: 0.11107185184717305\n","Epoch 17, Loss: 0.10493512323070596\n","Epoch 18, Loss: 0.09974556757625677\n","Epoch 19, Loss: 0.09426042076740374\n","Epoch 20, Loss: 0.0899634940593418\n","Epoch 1, Loss: 0.665382676700285\n","Epoch 2, Loss: 0.34241731750018306\n","Epoch 3, Loss: 0.297920869301949\n","Epoch 4, Loss: 0.2670985201417383\n","Epoch 5, Loss: 0.2431565692016819\n","Epoch 6, Loss: 0.2218290391658097\n","Epoch 7, Loss: 0.20395076278446198\n","Epoch 8, Loss: 0.18799920419433605\n","Epoch 9, Loss: 0.17479167143299953\n","Epoch 10, Loss: 0.16250908582894277\n","Epoch 11, Loss: 0.15198524942450814\n","Epoch 12, Loss: 0.14297516597137014\n","Epoch 13, Loss: 0.134831880501259\n","Epoch 14, Loss: 0.1273986631805804\n","Epoch 15, Loss: 0.12075743319065586\n","Epoch 16, Loss: 0.11477813059722246\n","Epoch 17, Loss: 0.10869822900361026\n","Epoch 18, Loss: 0.10364075567223814\n","Epoch 19, Loss: 0.09899608427579247\n","Epoch 20, Loss: 0.09409127628970851\n","Epoch 1, Loss: 0.7031536368228225\n","Epoch 2, Loss: 0.3402120633197746\n","Epoch 3, Loss: 0.2919281863613423\n","Epoch 4, Loss: 0.2603475372753799\n","Epoch 5, Loss: 0.2349942680011426\n","Epoch 6, Loss: 0.2149082606018924\n","Epoch 7, Loss: 0.19745817900037588\n","Epoch 8, Loss: 0.18224189127050738\n","Epoch 9, Loss: 0.17030189081089203\n","Epoch 10, Loss: 0.15877458282402837\n","Epoch 11, Loss: 0.14908306471018523\n","Epoch 12, Loss: 0.14009464405445274\n","Epoch 13, Loss: 0.13252703359982035\n","Epoch 14, Loss: 0.12579427574123783\n","Epoch 15, Loss: 0.1196786940379787\n","Epoch 16, Loss: 0.1132928904697998\n","Epoch 17, Loss: 0.10806513106279662\n","Epoch 18, Loss: 0.10325015506157076\n","Epoch 19, Loss: 0.09847105595606889\n","Epoch 20, Loss: 0.09422611221988826\n","Epoch 1, Loss: 0.6498357919074579\n","Epoch 2, Loss: 0.3334427239146949\n","Epoch 3, Loss: 0.2893625751121847\n","Epoch 4, Loss: 0.2598093752342183\n","Epoch 5, Loss: 0.23559268084225624\n","Epoch 6, Loss: 0.21467782089165025\n","Epoch 7, Loss: 0.19620750681646087\n","Epoch 8, Loss: 0.18065187825299084\n","Epoch 9, Loss: 0.16676850538295723\n","Epoch 10, Loss: 0.15495590757983707\n","Epoch 11, Loss: 0.14472056873071232\n","Epoch 12, Loss: 0.1354450688802643\n","Epoch 13, Loss: 0.12678640802849583\n","Epoch 14, Loss: 0.11949468521810354\n","Epoch 15, Loss: 0.11275336208211174\n","Epoch 16, Loss: 0.10676107893108146\n","Epoch 17, Loss: 0.10146598199080588\n","Epoch 18, Loss: 0.09687054636222976\n","Epoch 19, Loss: 0.09153268992630785\n","Epoch 20, Loss: 0.08704654022908287\n","Epoch 1, Loss: 0.695045479293317\n","Epoch 2, Loss: 0.34514718872111744\n","Epoch 3, Loss: 0.3003289916876283\n","Epoch 4, Loss: 0.27296398070924827\n","Epoch 5, Loss: 0.24941969850360712\n","Epoch 6, Loss: 0.2290858651386268\n","Epoch 7, Loss: 0.21192202503397775\n","Epoch 8, Loss: 0.19704132828551696\n","Epoch 9, Loss: 0.18300255365383777\n","Epoch 10, Loss: 0.1707268172104571\n","Epoch 11, Loss: 0.15933887730799376\n","Epoch 12, Loss: 0.1498748641302273\n","Epoch 13, Loss: 0.14038359999521646\n","Epoch 14, Loss: 0.13201269066370308\n","Epoch 15, Loss: 0.12518840830232988\n","Epoch 16, Loss: 0.11828221107668269\n","Epoch 17, Loss: 0.11235666479557943\n","Epoch 18, Loss: 0.10678500587096823\n","Epoch 19, Loss: 0.10186974405110485\n","Epoch 20, Loss: 0.09704033420411254\n","Epoch 1, Loss: 0.6587468125640965\n","Epoch 2, Loss: 0.33653067419333244\n","Epoch 3, Loss: 0.28810224334981394\n","Epoch 4, Loss: 0.25582288335492487\n","Epoch 5, Loss: 0.22986152986568936\n","Epoch 6, Loss: 0.20884516349098067\n","Epoch 7, Loss: 0.1903184243301148\n","Epoch 8, Loss: 0.17519972521835553\n","Epoch 9, Loss: 0.16164366004944863\n","Epoch 10, Loss: 0.1497512181549629\n","Epoch 11, Loss: 0.1391656616392897\n","Epoch 12, Loss: 0.13074983988028727\n","Epoch 13, Loss: 0.12323964321449685\n","Epoch 14, Loss: 0.11554884688773834\n","Epoch 15, Loss: 0.10968608870061794\n","Epoch 16, Loss: 0.10420733368866193\n","Epoch 17, Loss: 0.0991647712129758\n","Epoch 18, Loss: 0.09379354172022834\n","Epoch 19, Loss: 0.08964065896239934\n","Epoch 20, Loss: 0.08549998478114065\n","Epoch 1, Loss: 0.6881302980058737\n","Epoch 2, Loss: 0.33761409536671283\n","Epoch 3, Loss: 0.2923742958954148\n","Epoch 4, Loss: 0.2629520452932826\n","Epoch 5, Loss: 0.2389531944598407\n","Epoch 6, Loss: 0.21757234032474346\n","Epoch 7, Loss: 0.20042597332885906\n","Epoch 8, Loss: 0.18444622442253364\n","Epoch 9, Loss: 0.17083077402566987\n","Epoch 10, Loss: 0.1591821825707645\n","Epoch 11, Loss: 0.14885312240165688\n","Epoch 12, Loss: 0.1390272610659983\n","Epoch 13, Loss: 0.13125275077818555\n","Epoch 14, Loss: 0.12438556018954655\n","Epoch 15, Loss: 0.11742843429285929\n","Epoch 16, Loss: 0.11174299740202741\n","Epoch 17, Loss: 0.10639396938346406\n","Epoch 18, Loss: 0.10078770602479387\n","Epoch 19, Loss: 0.09668076185108439\n","Epoch 20, Loss: 0.0922751292131587\n","Accuracy on the test set: 97.41366666666666%\n"]}]},{"cell_type":"markdown","source":["#Adam and Orthogonal"],"metadata":{"id":"frAk7gH-5JIp"}},{"cell_type":"code","source":["accuracy4 = 0\n","for _ in range(10):\n","  # Initialize the model, loss function, and optimizer\n","  net5 = CustomNeuralNetwork2()\n","  criterion5 = nn.CrossEntropyLoss()\n","  optimizer5 = optim.Adam(net5.parameters(), lr=0.01)  # Use Adam optimizer\n","  num_epochs = 20\n","\n","  for epoch in range(num_epochs):\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          inputs, labels = data\n","          optimizer5.zero_grad()\n","          outputs = net5(inputs)\n","          loss = criterion5(outputs, labels)\n","          loss.backward()\n","          optimizer5.step()\n","          running_loss += loss.item()\n","      # print(f'Epoch {epoch + 1}, Loss: {running_loss / len(trainloader)}')\n","\n","  # Testing the model\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():\n","      for data in trainloader:\n","          images, labels = data\n","          outputs = net5(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += labels.size(0)\n","          correct += (predicted == labels).sum().item()\n","\n","  accuracy4 += 100 * correct / total\n","\n","print(f'Accuracy on the test set: {accuracy4/10}%')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6crXHI1-5McM","executionInfo":{"status":"ok","timestamp":1695303374781,"user_tz":-360,"elapsed":4284904,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"5e2b5dc1-4640-4551-e09b-21321eb71737"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on the test set: 95.97733333333333%\n"]}]},{"cell_type":"markdown","source":["#Benchmarking"],"metadata":{"id":"nV8GwSBqy3hp"}},{"cell_type":"code","source":["# Create a bar chart to compare accuracies\n","accuracy1 = 97.76166666666666\n","accuracy2 = 95.45366666666665\n","accuracy3 = 97.41366666666666\n","accuracy4 = 95.97733333333333\n","\n","import matplotlib.pyplot as plt\n","models = ['SGD+X','Adam+X','SGD+O','Adam+O']\n","accuracies = [accuracy1, accuracy2, accuracy3, accuracy4]\n","\n","plt.bar(models, accuracies)\n","plt.xlabel('Models')\n","plt.ylabel('Accuracy (%)')\n","plt.title('Comparison of Mean Model Accuracies')\n","plt.ylim(90, 100)  # Set the y-axis range from 0% to 100%\n","plt.show()"],"metadata":{"id":"fyWAFkv3Ug7_","colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"status":"ok","timestamp":1695303483582,"user_tz":-360,"elapsed":6,"user":{"displayName":"Zaed Khan","userId":"13504418901449263064"}},"outputId":"451d2d3e-4bee-4bbc-f3d1-b10dc631a10a"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}